{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project: Automatic Signal Detector_1-2_tasks.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qNmyPyaYvcXv"
      ],
      "authorship_tag": "ABX9TyN14LpngqEXr9uEByNdBDxw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lilly-yang/UCA--Machine_Learning_and_Computer_Vision/blob/main/Project_Automatic_Signal_Detector_1_2_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7TX2_1AxL4Z"
      },
      "source": [
        "# **Automatic Signal Detector**\n",
        "Task 1 - Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV-Se7BUzCZ9"
      },
      "source": [
        "## README\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZFgkdE6zLY-"
      },
      "source": [
        "The goal of this progress is to automatically detect face.\n",
        "- Reads the camera in Google Colab and run facedetect\n",
        "- Reduce the computation time of Facedetect\n",
        "\n",
        "\n",
        "### Getting Started\n",
        "There is a model (.xml file) in my Google driver will be used in this progress. Make sure you are mounted [my Google driver](https://drive.google.com/drive/folders/1SyAjYyn7sxlJULhwh1kkbA71xfAGkk2A?usp=sharing).\n",
        "\n",
        "_haarcascade_frontalface_alt.xml_\n",
        "\n",
        "\n",
        "### Running the progress\n",
        "1. Running cells in each part\n",
        "2. Runing cell of `main()` to start face detection\n",
        "\n",
        "\n",
        "### Authors\n",
        "Li YANG   li.yang-li@etu.univ-cotedazur.fr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNmyPyaYvcXv"
      },
      "source": [
        "## Mounted Google Driver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfBLzs2PkdFb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "17de7d6a-dcf8-45cb-f57e-dd1c8ad81c41"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2viqYx97hPMi"
      },
      "source": [
        "## Camera Capture\n",
        "Using a webcam by JavaScript code to capture images in Google Colab for processing on the runtime.\n",
        "\n",
        "PS: this cell of code (except comments) were copied from our course webpage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SucxddsPhOmj"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode,b64encode\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# capture camera image by JavaScript code in Google Colab\n",
        "def VideoCapture():\n",
        "  js = Javascript('''\n",
        "    async function create(){\n",
        "      div = document.createElement('div');\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.setAttribute('playsinline', '');\n",
        "\n",
        "      div.appendChild(video);\n",
        "\n",
        "      stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: \"environment\"}});\n",
        "      video.srcObject = stream;\n",
        "\n",
        "      await video.play();\n",
        "\n",
        "      canvas =  document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "      div_out = document.createElement('div');\n",
        "      document.body.appendChild(div_out);\n",
        "      img = document.createElement('img');\n",
        "      div_out.appendChild(img);\n",
        "    }\n",
        "\n",
        "    async function capture(){\n",
        "        return await new Promise(function(resolve, reject){\n",
        "            pendingResolve = resolve;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            result = canvas.toDataURL('image/jpeg', 0.8);\n",
        "            pendingResolve(result);\n",
        "        })\n",
        "    }\n",
        "\n",
        "    function showimg(imgb64){\n",
        "        img.src = \"data:image/jpg;base64,\" + imgb64;\n",
        "    }\n",
        "\n",
        "  ''')\n",
        "  display(js)\n",
        "\n",
        "def byte2image(byte):\n",
        "  jpeg = b64decode(byte.split(',')[1])\n",
        "  im = Image.open(io.BytesIO(jpeg))\n",
        "  return np.array(im)\n",
        "\n",
        "def image2byte(image):\n",
        "  image = Image.fromarray(image)\n",
        "  buffer = io.BytesIO()\n",
        "  image.save(buffer, 'jpeg')\n",
        "  buffer.seek(0)\n",
        "  x = b64encode(buffer.read()).decode('utf-8')\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eQ47NF3wien"
      },
      "source": [
        "## Face Detection\n",
        "This progress use haar cascades.\n",
        "\n",
        "USAGE: `facedetect.py [--cascade <cascade_fn>] [--nested-cascade <cascade_fn>] [<video_source>]`\n",
        "\n",
        "Below are some import and functions copied from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsM11rBLsg7d"
      },
      "source": [
        "## Python 2/3 compatibility\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow\n",
        "import sys, getopt\n",
        "\n",
        "\n",
        "## Some useful functions were copied form local files\n",
        "## Function for timing\n",
        "def clock():\n",
        "    return cv.getTickCount() / cv.getTickFrequency()\n",
        "\n",
        "## Function for imformation presentation of captured image\n",
        "def draw_str(dst, target, s):\n",
        "    x, y = target\n",
        "    cv.putText(dst, s, (x+1, y+1), cv.FONT_HERSHEY_PLAIN, 1.0, (0, 0, 0), thickness = 2, lineType=cv.LINE_AA)\n",
        "    cv.putText(dst, s, (x, y), cv.FONT_HERSHEY_PLAIN, 1.0, (255, 255, 255), lineType=cv.LINE_AA)\n",
        "\n",
        "\n",
        "## Detect face by trained model in each grid of the giving image:\n",
        "##   if there is a face in the image then return the indexation of the rectangel are\n",
        "##   if there is not any face in the image then return a empty list: []\n",
        "def detect(img, cascade):\n",
        "    rects = cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=4, minSize=(30, 30),\n",
        "                                     flags=cv.CASCADE_SCALE_IMAGE)\n",
        "    if len(rects) == 0:\n",
        "        return []\n",
        "    rects[:,2:] += rects[:,:2]\n",
        "    return rects\n",
        "\n",
        "## Drawing a rectangle on image by giving indexation\n",
        "def draw_rects(img, rects, color):\n",
        "    for x1, y1, x2, y2 in rects:\n",
        "        cv.rectangle(img, (x1, y1), (x2, y2), color, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0ZYPxscQIBu"
      },
      "source": [
        "Main function of Face detectation:\n",
        "* Face detection\n",
        "* Part of Reducing time of detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h77UZSlgQEGD"
      },
      "source": [
        "def main():\n",
        "    ## Loding models from Google Driver \n",
        "    cascade_fn = \"/content/drive/My Drive/MLCV/haarcascade_frontalface_alt.xml\"\n",
        "    cascade = cv.CascadeClassifier(cv.samples.findFile(cascade_fn))\n",
        "\n",
        "    ## initial camera caoture function\n",
        "    VideoCapture()\n",
        "    eval_js('create()')\n",
        "\n",
        "    ## Main function of On-time Face Detection\n",
        "    rects = []  # initial rects as [] for detect face from whole image\n",
        "\n",
        "    while True:\n",
        "      ## capture image and tralate to array d-type\n",
        "      byte = eval_js('capture()')\n",
        "      img = byte2image(byte)\n",
        "      # print(np.shape(img))  # (480, 640, 3)\n",
        "\n",
        "      gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "      \n",
        "      # Reduce the computation time of not-first Facedetect\n",
        "      if len(rects) == 0:\n",
        "        # print('Detect the whole image!')\n",
        "        gray = cv.equalizeHist(gray)\n",
        "        change = 0\n",
        "      else:\n",
        "        ## if there are face in image, narrow the detected are near to the face\n",
        "        (x1, y1, x2, y2) = rects[0]\n",
        "        xx1 = x1-20 if x1>20 else 0\n",
        "        yy1 = y1-20 if y1>20 else 0\n",
        "        xx2 = x2+20 if x2+20 < 640 else 640\n",
        "        yy2 = y2+20 if y2+20 < 480 else 480\n",
        "        # print('Get face at: ', rects[0], 'New detecting grid is:', [xx1, yy1, xx2, yy2])\n",
        "        gray = cv.equalizeHist(gray[yy1:yy2, xx1:xx2])\n",
        "        change = 1\n",
        "\n",
        "      ## get time of start detectation\n",
        "      t = clock()\n",
        "      ## detect giving image by model\n",
        "      rects = detect(gray, cascade)\n",
        "\n",
        "      ## Drawing detected face on image\n",
        "      if len(rects) != 0:\n",
        "        ## Restore coordinates to original size\n",
        "        if change:\n",
        "          # print('Detected index from smaller grid:', x1, y1, x2, y2)\n",
        "          x1, y1, x2, y2 = rects[0]\n",
        "          x1, y1, x2, y2 = x1+xx1, y1+yy1, x2+xx1, y2+yy1\n",
        "          rects = [[x1, y1, x2, y2]]\n",
        "          # print('Re-index to oranginal image:', rects[0])\n",
        "      \n",
        "        draw_rects(img, rects, (0, 255, 0))\n",
        "      # else:\n",
        "        # print('No face!')\n",
        "      dt = clock() - t\n",
        "\n",
        "      draw_str(img, (20, 20), 'time: %.1f ms' % (dt*1000))\n",
        "      print('time: %.1f ms' % (dt*1000))\n",
        "\n",
        "      eval_js('showimg(\"{}\")'.format(image2byte(img)))\n",
        "\n",
        "      if cv.waitKey(5) == 27:\n",
        "          break\n",
        "\n",
        "    print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbNSFJrh_ftL"
      },
      "source": [
        "Excuting Face-Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_D4SCHE4K8T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "8e7ea96b-9dd4-4cdd-bc85-ebbec4fa1997"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
          ]
        }
      ]
    }
  ]
}